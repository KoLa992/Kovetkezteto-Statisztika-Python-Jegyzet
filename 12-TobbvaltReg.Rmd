# Többváltozós OLS Regresszió alapjai

## Magyar járások COVID-19 halálozási arányai

A <a href="https://github.com/KoLa992/Kovetkezteto-Statisztika-Python-Jegyzet/blob/main/COVID_JarasData.xlsx" target="_blank">COVID_JarasData.xlsx</a> fájl egy olyan adattábla, ami 102 magyar járásról (azokról, ahol a kórházak 2019-ben átlagos vagy átlag alatti leterheltségűek voltak a [NEAK adatai](http://www.neak.gov.hu/data/cms1026624/Korhazi_agyszamkimutatas_2019.pdf) alapján) 5 változó (oszlop) adatát tárolja:

- **Jaras**: A járás neve
- **COVIDHalal**: COVID-19 halálozási arány: elhunytak / fertőzöttek hányadosa (%) 2021.03.04-én. Forrás: [atlatszo.hu](https://bit.ly/COVID-adatok)
- **Apolok**: Háziorvosi szakápolók/ápolók száma 10000 főre (2019) Forrás: KSH
- **Munkanelkuliseg**: Nyilvántartott álláskeresők száma 10000 főre (2019) Forrás: KSH
- **Nok65Felett**: Lakónépességből a 65 éves és idősebb nők aránya (%) (2019) Forrás: KSH

Olvassuk be a fájlt egy pandas `data frame`-be a pandas sima `read_excel` függvényével: 

```{python}
# Elemzéshez és ábrázoláshoz szükséges csomagok betöltése
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as stats

# 102 járás adatainak beolvasása
covid = pd.read_excel("COVID_JarasData.xlsx")
covid.info()
```

Láthatjuk, hogy megvan minden oszlop, amit a leírásban megadtunk. Megvan mind a négy numerikus (azaz `float`, mert törtszámokról van szó) típusú oszlopunk, és a **Jaras** oszlop maradhat `object`, azaz "szöveges" adattípusban, hiszen ez a járások azonosítója, minden név csak egyszer fordul elő a táblában, statisztikai elemzéseknek értelemszerűen nem vetjük alá ezt a változót. :)

Adja magát a dolog, hogy  megpróbáljuk **kétváltozós regressziókkal** elemezni azt, hogy miképpen függ a vizsgált járásokban a COVID halálozási arány a másik három változótól (ápolók, munkanélküliek száma 10 ezer főre, 65 éven felüli nők aránya).

Első logikus gondolat azt diktálja, hogy hát minél több ápolója van népességarányosan egy járásnak, annál kevesebb lesz a COVID halálozási arány, hiszen a több ápoló jobba ellátást tud biztosítani. Teszteljük is le az elméletünket: csináljunk egy regressziót, ahol eredményváltozó ($Y$) a **COVIDHalal**, magyarázóváltozó ($X$) pedig az **Apolok**!

Első körben nézzük meg egy $R^2$ segítségével milyen szoros a két változónk köztü kapcsolat:

```{python}
(stats.pearsonr(covid.Apolok, covid.COVIDHalal)[0]**2)*100
```

Alapvetően az $R^2$ szép, korrekt dolgokat mutat. Az ápolók száma kb. 18 %-ban megmagyarázza a COVID halálozás alakulását a vizsgált járások körében ($R^2=17.6\%$), ami egy közepes magyarázóerőnek minősíthető, hiszen $10\% < R^2 < 50\%$.

Nézzük meg, hogy néz ki a regressziós egyenes egyenlete! Használjuk nyugodtan a <a href="https://kola992.github.io/Kovetkezteto-Statisztika-Python-Jegyzet/k%C3%A9tv%C3%A1ltoz%C3%B3s-line%C3%A1ris-regresszi%C3%B3.html#egy-gyakorl%C3%B3-p%C3%A9lda-covid-adatokon" target="_blank">12.6. fejezetben</a> megismert `polyfit` függvényét a `numpy` csomagnak:

```{python}
Beta1, Beta0 = np.polyfit(covid.Apolok, covid.COVIDHalal, deg = 1)
print([Beta1, Beta0])
```

A 102 járás adatából illesztett regressziós modell szerint tehát: $$Becsult COVIDHalal= 0.36 \times Apolok + 2.02$$

**Ajjajjaj!** A modell **meredeksége pozitív**!! Konkrétan, ha a járásban az ápolók száma 10 ezer főre nő 1-gyel, akkor várhatóan a COVID halálozási arány is **növekedni** fog 0.36 százalékponttal! Ez alapján úgy tűnik, hogy mintha megérné kevesebb ápolót tartani, mert akkor fog csökkenni a COVID halálozás a járásban. Ezt az eredményt így nagyon nem eszi meg a gyomrunk!

A fura eredmény háttérben egy úgynevezett **confunding** nevű jelenség áll!

Lessük csak meg a minden **covid** `data frame`-ben lévő numerikus változó korrelációmátrixát! Ez egy oylan táblázat, amiben az egyes numerikus változók közti korrelációkat mutatja meg nekünk a gépállat. Simán egy `data frame` numerikus változóiból a `data frame` numerikus oszlopain (mindegyik kivéve az elsőt) elsütött `cor` metódussal hívható elő.

```{python}
covid.iloc[:,1:5].corr()
```

A korrelációkból látszik, hogy a **COVIDHalal** változóval a másik három változó egyirányú, és közepes erősségű kapcsolatban állnak (mindegyik korreláció a COVIDHalal oszlopában, ami nem az önmagával vett korrelációt jelenti az +0.4 körüli érték). Ez a **Munkanelkuliseg** és **Nok65Felett** változók esetén logikus is, hiszen a COVID elsősorban a 65 év felettiek körében halálos, illetve azok körében ahol eleve több alapbetegség jelen volt. Ahol magas a munkanélküliség, ott pedig eleve rosszabb az egészségi állapot: alkoholizmus, szív- és érrendszeri problémák gyakoriak a magas munkanélküliségű járásokban (lásd pl. [ezt a tanulmányt](https://reader.elsevier.com/reader/sd/pii/S0927537120300609?token=E1AD2E1805FB5308BC40754433D867BE2D6F2FEC1EECA824AFAFC2F37BF35723550C07B43E62BE53CD9F6822494FF445&originRegion=eu-west-1&originCreation=20211005092903)).<br>
NODE, az **Apolok** egyirányú módon és közepes erősségben összefügg a **Munkanelkuliseg** és **Nok65Felett** változókkal is! Tehát, valószínűleg a magas 10 ezer főre jutó ápolószámmal bíró járásokban *csak azért magas a COVID halálozás*, mert ezekben a járásokban magas a munkanélküliség és az idős népesség aránya is! Tehát a népesség egészségi állapota ezen járásokban **eleve rosszabb**!<br>
Na, ez a jelenség a **confunding**: amikor egy változó csak azért korrelál egy másikkal, mert **valójában egy vagy több másik változó hatását közvetíti a saját hatásán túl**.

Szóval, a feladat adott: fejtsük meg, hogy ha leválasztjuk az **Apolok** változóról a **Munkanelkuliseg** és **Nok65Felett** változók hatását (azaz kiszűrjük/megtisztítjuk a *confunding* hatást), akkor hogyan hat az **Apolok** változó **önállóan** a **COVIDHalal**-ra!<br>
Erre a feladatra eszözünk a **többváltozós lineáris regresszió**! Ami egyszerűen a sima $\hat{Y}=\beta_1 X + \beta_0$ kétváltozós regresszió kiterjesztése úgy, hogy az egyenletbe tetszőleges, konkrétan $k$ db magyarázóváltozót rakunk be, és mindenkinek meglesz a maga $\beta$-ja:
$$\hat{Y}=\beta_1 X_1 + \beta_2 X_2 + ... + \beta_k X_k + \beta_0$$

Az előbbi egyenlet alapján a **többváltozós lineáris regresszió**t úgy is értelmezhetjük, mint egy olyan statisztikai modellt, ami a COVID halálozási arányokat akarja előrejelezni **egyszerre az ápolószám, munkanélküliség és 65 év feletti női népesség aránya** segítségével!

## A Többváltozós Lineáris Regresszió OLS elvű előállítása

A nagy szerencsénk, hogy a többváltozós regresszióban is lényegében változtatás nélkül működik a $\beta_j$-k OLS elvű meghatározási módja.<br>
Azaz, úgy választjuk meg a $\beta_j$-ket, hogy az COVID halálozási arányokra ($Y$) adott becsléseink hibája minimális legyen. A becslési hibát az ún. SSE mutatóval mérjük továbbra is: $Sum of Squared Errors (SSE) = \sum_{i=1}^n(y_i-\hat{y_i})^2$.<br>

Az továbbra is igaz lesz, hogy négyzetesen mért hiba esetében a gép itt **sem vaktában keresi** a $\beta$-kat! Az OLS feladat megoldása (tehát a legkisebb $SSE$-t adó $\beta$-k) kifejezhetők egy fix képlettel itt is!

Az $SSE=\sum_{i=1}^n(y_i-\hat{y_i})^2=\sum_{i}(y_i-\sum_{j}\beta_jx_j)^2$ képlet kifejezhető mátrixosan is, ha bevezetjük az $X$ mátrikot, aminek az első oszlopa csupa 1-et tartalmaz (a tengelymetszet miatt) és a többi oszlopaiba az $X_j$-ket rakjuk, akkor az $SSE$-t így is fel tudjuk írni: $SSE=||y-X\beta||^2$. Ha ezt a mátrixosan kifejezett függvényt deriváljuk a $\beta$-k szerint, és a deriváltakat egyenlővé tesszük 0-val, akkor kifejezhető az a fix formula, amivel az OLS elven számított $\beta$-k vektora megadható: $\beta=(X^TX)^{-1}X^Ty$.

Azt, hogy konkrétan hogyan jön ki ez a csodaszép mátrixos formula, nekünk annyira nem fontos. A gyakorlati szempontból azt kell látni, hogy minimalizálási feladathoz többváltozós regresszió esetén sem kell a 3. gyakorlaton látott `optim` függvény, mert a megoldása egy fix mátrixos képlet. **Emiatt használják az OLS regressziót mai napig előszeretettel: fix képlettel megadhatók a $\beta$ együtthatók többváltozós esetben is!**

Az a nagy szerencse, hogy a mi három magyarázóváltozót használó modellünk együtthatóit ilyen OLS elven meg lehet becsültetni Pythonban a `statsmodels` csomag `OLS` nevű függvényével. Ehhez először importáljuk a csomag függvényeit egy `sm` c. névtérbe.

```{python}
import statsmodels.api as sm
```

A függvény használatához először el kell különíteni egy külön objektumba az eredményváltozó oszlopát a vizsgált `data frame`-ből. Hívjuk most ezt az objetktumot `Y`-nak.

```{python}
Y = covid.COVIDHalal
```

Majd ezek után egy külön `data frame`-be összegyűjtöm csak a magyarázóváltozókat, hívjuk ezt az új `data frame`-t most szimplán `X`-nek. Utána a `statsmodels` csomag `add_constant` függvényével hozzáadunk egy csupa $1$-ből álló oszlopot, ahogy a regresszió korábban látott mátrixos felírásában is vettük az $X$ mátrixot.

```{python}
X = covid.loc[:,['Apolok','Munkanelkuliseg','Nok65Felett']]
X = sm.add_constant(X)
X
```

És végül akkor az `sm` névtér `OLS` függvényébe berakjuk ezeket az újonnan létrehozott `Y` és `X` Python objektumokat (kötelezően ebben a sorrendben), és végül meghívunk az egészen egy `fit()` metódust. Az eredményt pedig egy külön Python objektumba kell elmenteni.

```{python}
sokvalt_modell = sm.OLS(Y,X).fit()
```

A többváltozós regressziós modell legfontosabb statisztikai mutatóit egy nap összefoglaló táblázatban az az újonnan létrehozott `sokvalt_modell` objektum `summary()` metódusával lehet lekérdezni.

```{python}
print(sokvalt_modell.summary())
```

Nézzük meg mit látunk a `summary` eredményeként:

- Mivel az OLS elvű becslése, tehát a teljes modellhiba $SSE$ elvű mérése megmaradt, így $R^2$-et továbbra is tudunk számolni $R^2=1-\frac{SSE}{SST}$ módon. Az értelmezése pedig annyiban módosul, hogy azt adja meg **hány százalékban magyarázza az eredményváltozót a magyarázóváltozók összessége**. Arra figyeljünk, az előbbi értelmezés miatt, hogy korreláció négyzeteként már **NEM** számolható a mutató, hiszen korreláció *egyszerre csak két változó kapcsolatát tudja leírni*, kettőnél több több változóét már nem. Ez alapján jelen szituációban azt mondhatjuk el, hogy az ápolók száma, 65 feletti női népesség aránya és munkanélküliség **együtt** $34\%$-ban magyarázzák a COVID halálozási arányok ingadozását a járások között. Ez érezhető magyarázóerő növekedés a kétváltozós modellhez képest, ahol csak az **Apolok** hatását vizsgáltuk.
- A Globális F-próba p-értéke most is jó alacsony, mivel `Prob (F-statistic)` = $6.42 \times 10^{-9}$. Tehát, nem meglepő módon azt mondhatjuk, hogy minden szokásos $\alpha$-n elutasíthatjuk, azt a $H_0$-t, hogy az $R^2$ összeomlik 0-ba a mintán kívüli világban. Amit itt érdemes megfigyelni az a p-érték számoláshoz használt F-eloszlás szabadságfokai. Most nekünk ugye $k=3$ magyarázóváltozónk van, az azt jelenti, hogy a regresszióban $p=4$ paramétert, azaz $\beta_j$-t kellett megbecsülnie az OLS-nek a tengelymetszet miatt. Ez alapján az F-eloszlás első szabadságfoka $p-1=3=k$, míg a második szabadságfok $n-p=102-4=98=n-k-1$.
- Ezen kívül az F-próba hipotéziseit úgy is fel lehet írni, mint: $H_0: \beta_j=0 \forall j$, azaz minden $\beta$ a mintán kívüli világban 0-nak vehető, semminek nincs magyarázóereje $Y$-ra. És $H_1: \exists j:\beta_j \neq 0$, tehát van legalább egy darab $\beta$, ami nem nulla a mintán kívüli világban, és a hozzá tartozó $X_j$-nek van hatása $Y$-ra a mintán kívüli világban is.

A `Coefficients` táblából ismét felírható a megbecsült modell egyenlete: $$BecsultCOVIDHalal=0.04 \times Apolok + 0.003 \times Munkanelkuliseg + 0.27 \times Nok65Felett - 0.15$$

Az egyenlet olyan szempontból furának tűnik, hogy az **Apolok** együtthatója még mindig pozitív, bár tény, hogy már csak $0.04$ az értéke a kétváltozós modell $0.36$-os meredeksége helyett.<br>
Ahhoz, hogy pontosan megértsük mit is takar ez a $0.04$ és megadjuk hogyan lehet megmérni egy magyarázóváltozó ($X_j$) fontosságát a regressziós modellünk előrejelzéseiben, egy kicsit alaposabban meg kell érteni mit is takarnak ezek a $\beta_j$ értékek a többváltozós regresszióban.

## A magyarázóváltozók marginális hatása

Ahogyan a 2. fejezetben írtam, a az OLS regressziót azért használják a mai napig előszeretettel, mert fix képlettel megadhatók a $\beta_j$ együtthatók. De ez csak az egyik oka a modell népszerűségének. A másik az, hogy a $\beta_j$ együtthatók megfeleltethetők a hozzájuk tartozó $X_j$ magyarázóváltozók **marginális hatásának**.

Az $X_j$ magyarázóváltozó marginális hatása az a hatás, amit ő **egyedül és közvetlenül** fejt ki az $Y$ eredményváltozó alakulására. OLS regresszióban ez a marginális hatás $X_j$ magyarázóváltozó esetében épp a $\beta_j$ együttható lesz.

Most ez alapján egy $\beta_j$ általános értelmezése a következő: **Ha az adott bétához tartozó magyarázóváltozó értéke egy egységgel nő a többi magyarázóváltozó értékének változatlansága mellett, akkor az eredményváltozó értéke várhatóan bétányit változik.**

Ennek az értelmezésnek **3 kötelező eposzi kelléke** van:

1. Minden változás az eredményváltozó és az éppen vizsgált magyarázóváltozó **saját mértékegységében** értendő
2. Az éppen nem vizsgált magyarázóváltozók értékéről feltesszük, hogy nem változnak. Ezzel az éppen vizsgált $X_j$ közvetlen hatását mérjük meg $Y$-ra. Ez a **ceteris paribus elv**.
3. A $\beta_j$ az $Y$-ban okozott **várható** változást mutatja csak! Ez a változás akkor lenne egész biztosan épp $\beta_j$-nyi, ha $R^2=100\%$ lenne.

Ha ez az értelemzés így általánosságban igaz, akkor az **Apolok** $+0.04$-es $\beta$-ja a többváltozós regressziónkban már megtisztult a munkanélküliség és a 65 év feletti népesség **confunding** hatásától, hiszen a $0.04$ egy ezek megváltozása *nélküli* +1 egység **Apolok** növekedés esetén mutatja be a COVID halálozás várható változását.

Ezek alapján nézzük meg a jelenlegi modellünkben vett $\beta_j$-k értelmezése! Ha csak a modell $\beta_j$-it akarom lekérdezni és semmi egyebet, akkor azt a modellt tartalmazó Python objektum `params` tulajdonságának lekérdezésével tudom megtenni.

```{python}
sokvalt_modell.params
```

- $\beta_1=0.04$: Ha egy járásban a 10 ezer főre jutó ápolók száma nő 1 fővel változatlan munkanélküliség és 65 év feletti női népesség mellett, akkor a járás COVID halálozási aránya várhatóan 0.04 százalékponttal emelkedik. Ez még mindig nem tűnik szimpatikusnak, de majd mindjárt a végére járunk.
- $\beta_2=0.003$: Ha egy járásban az álláskeresők száma 10 ezer fővel (azaz a 10 ezer főre jutó álláskeresők száma 1 fővel) nő változatlan ápolószám és 65 év feletti női népesség mellett, akkor a járás COVID halálozási aránya várhatóan 0.003 százalékponttal emelkedik. Egy fokkal magyarosabban: Ha két azonos ápolószámú és azonos 65 év feletti női népességgel bíró járás közül az egyiknek 10 ezer fővel több munkanélkülije van, akkor ott várhatóan 0.003 százalékponttal nagyobb esélye van egy COVID fertőzöttnek meghalni.
- $\beta_3=0.27$: Ha egy járásban a 65 év feletti női népesség aránya 1 százalékponttal nő változatlan ápolószám és munkanélküliség mellett, akkor a járás COVID halálozási aránya várhatóan 0.27 százalékponttal emelkedik. Egy fokkal magyarosabban: Ha két azonos ápolószámú és munkanélüliségű járás közül az egyik népességében 1 százalékponttal több lesz a 65 év feletti nők aránya, akkor ott várhatóan 0.27 százalékponttal nagyobb esélye van egy COVID fertőzöttnek meghalni.

Persze van még **egy $\beta_0$ tengelymetszetünk, ami hivatalosan azt mutatja meg, hogy mennyi lenne az $\hat{Y}$, ha a modellben minden magyarázóváltozó ($X_j$) 0 értéket venne fel**.<br>
Ez esetünkben azt jelenti, hogy egy 0 ápolójú, 65 év feletti nők nélküli és teljes foglalkoztatottságú járás COVID halálozási aránya a modellünk alapján $-0.15\%$. Nyilván ezzel az értelmezéssel most nem kell foglalkozni, mivel a $\forall X_j=0$ hely jelen tématerületen nem létezik. Ha valaki talál egy ilyen *csupa 0* járást, akkor viszont meneküljön onnan, mert jönnek a zombik :) (negatív halálozási arány :))

### Útelemzés

Az a tény, hogy többváltozós regresszióban a $\beta_j$ együtthatók megfeleltethetők a hozzájuk tartozó $X_j$ magyarázóváltozók **marginális hatásának**, elvezet minket az egyes $X_j$ magyarázóváltozók közvetlen és közvetett hatásának fogalmához. Egy tetszőleges $X_j$ magyarázóváltozó közvetlen és közvetett hatásait konkrétan, számszerűen is ki lehet fejezni a regressziós $\beta$-k segítségével.

Vegyük az eddig is vizsgált **Apolok** változó közvetlen és közvetett hatásait az alábbi ábrán szemléltetve az 1. fejezet korrelációmátrixából alapján kiindulva. Ugye a korrelációk alapján az volt az elképzelésünk, hogy **az ápolók száma csak azért lehet magas pozitív korrelációban a COVID halálozással, mert a nagyobb munkanélküliség jellemzően nagyobb ápolószámmal jár együtt, és a magas munkanélküliség megnövelte a COVID halálozást, az ápolószámnak meg lehet, hogy önállóan semmi hatása nincs**. Lássuk, hogy a **regressziós együtthatók igazolják-e ezt az elképzelést**!

<center>
![](Utelemzes.png){width=50%}
</center>

Itt a *piros* nyíl jelöli az **Apolok** közvetlen hatását a **COVIDHalal**-ra, míg a *kék* nyíl a **Munkanelkuliseg** közvetlen hatását a **COVIDHalal**-ra. A *zöld* nyíl pedig az **Apolok** hatása a **Munkanelkuliseg**-re.

A piros és kék nyilakon lévő közvetlen hatások nagyságát megadja a $BecsultCOVIDHalal=\beta_1 \times Apolok + \beta_2 \times Munkanelkuliseg + \beta_0$ regresszió $\beta_1$ és $\beta_2$ együtthatója. Szóval nyejük is ki ezeket a $\beta$-kat külön R objektumokba:

```{python}
# először legyártjuk a két magyarázóváltozós regressziót
X_ketvalt = covid.loc[:,['Apolok', 'Munkanelkuliseg']]
X_ketvalt = sm.add_constant(X_ketvalt)
ketmagyvalt_modell = sm.OLS(Y, X_ketvalt).fit()

# megnézzük az együtthatókat tartalmazó tömböt
ketmagyvalt_modell.params

# a tömb 2. és 3. elemét a neveik alapján elmentjük: figyeljünk, hogy a 0. indexű elem a Béta_0!
Beta_Apolok_COVID = ketmagyvalt_modell.params['Apolok']
Beta_Munkanelk_COVID = ketmagyvalt_modell.params['Munkanelkuliseg']
```

A zöld nyílon található hatás nagyságát pedig egyszerűen a $BecsultMunkanelkuliseg = \beta_1 \times Apolok + \beta_0$ kétváltozós regresszió $\beta_1$ együtthatója adja meg. Ezt is mentsük le külön Python objektumokba:

```{python}
# legyártjuk a két magyarázóváltozós regresszió együtthatóit, és a meredekség lesz a "zöld nyíl" értéke
Beta1_Apolok_Munkanelk, Beta0_Apolok_Munkanelk = np.polyfit(covid.Apolok, covid.Munkanelkuliseg, deg=1)
```

Ezzel pedig megadható az $Apolok \rightarrow COVIDHalal$ kapcsolat *közvetlen és közvetett* hatásai:

```{python}
# közvetlen hatása az ápolók számának a COVID halálozásra (piros nyíl)
Kozvetlen_Apolok_COVID = Beta_Apolok_COVID
Kozvetlen_Apolok_COVID

# közvetett hatása az ápolók számának a COVID halálozásra (zöld*kék nyíl)
Kozvetett_Apolok_COVID = Beta1_Apolok_Munkanelk * Beta_Munkanelk_COVID
Kozvetett_Apolok_COVID
```

Hiszen a **közvetett** hatás csupán annyi, hogy annyiszor kell venni a $Munkanelkuliseg \rightarrow COVIDHalal$ közvetlen hatást (kék nyíl), ahányszor megváltozik a **Munkanelkuliseg** egy egység **Apolok** növekedésre (zöld nyíl). Ezt pedig éppen a `Beta_Apolok_Munkanelk` adja meg!

Ezzel pedig megadható a $Apolok \rightarrow COVIDHalal$ kapcsolat *teljes* hatása:

```{python}
# teljes hatás = közvetlen + közvetett hatás
Teljes_Apolok_COVID = Kozvetlen_Apolok_COVID + Kozvetett_Apolok_COVID
Teljes_Apolok_COVID
```

És jé, ez az érték pont ugyan az, mint *az eredeti $BecsultCOVIDHalal = \beta_1 \times Apolok + \beta_0$ kétváltozós regresszió $\beta_1$ meredeksége! :)

```{python}
Beta1 # Ezt ugye még az 1. fejezetben hoztuk létre!
```

Tehát, tényleg az eredeti kétváltozós regresszióban lévő **confunding** hatást tudtuk letisztítani a többváltozós regresszióval az **Apolok** változóra nézve!

Nyilván hasonló módon lehetne megmérni, hogy mennyi az $Apolok \rightarrow COVIDHalal$ kapcsolatban a **Nok65Felett** változó *közvetett hatása* miatt fellépő **confunding** hatása a $BecsultCOVIDHalal = \beta_1 \times Apolok + \beta_0$ kétváltozós regresszió $\beta_1$ meredekségében.

### Parciális t-próba

A magyarázóváltozók fontosságát hipotézisvizsgálattal is meg tudjuk mérni. Egy tetszőleges $X_j$ magyarázóváltozó fontosságát az alábbi null- alteranatív hipotézis páros tesztelésével tudjuk megállapítani:

- $H_0: \beta_j=0$ ~ $X_j$ hatása $Y$-ra a mintán kívül **nem szignifikáns**
- $H_1: \beta_j\neq0$ ~ $X_j$ hatása $Y$-ra a mintán kívül **szignifikáns**

Tehát ebben a hipotézisvizsgálatban, amit *parciális t-próbának* fogunk hívni, **azt mondja a $H_0$, hogy $X_j$ hatása az eredményváltozóra csak egy mintavételi hiba, ha megfigyelnék új egyedeket (azaz új járásokat), akkor a mintában mért hatás megszűnne, azaz $\beta_j$ kinullázódna**.

Ehhez a hipotézisvizsgálathoz kell nekünk a Globális F-próbánál látottak alapján egy próbafüggvény és p-érték is.

A próbafüggvényhez ad nekünk a Python egy **standard mintavételi hibát, angolul standard errort**. Ez van a `summary` metódus által kigenerált együtthatótábla 2. oszlopában:

```{python}
print(sokvalt_modell.summary())
```

Itt pl. a $0.096$ érték azt jelenti, hogy az **Apolok** bétája a mintában 0.04, de ez az érték a megfigyelt mintán kívül, új járásokra is futtatva a regressziót, ingadozhat a 0.04 körül, *várhatóan* +- 0.096-tal. A $\beta_j$ és standard hibájának ($SH_j$) hányadosa lesz az ún. *t-érték = t value*, ami a parciális t-próba c. hipotézisvizsgálat próbafüggvénye. Az **Apolok** változó esetében ez 0.463

A próbafüggvény eloszlása sok-sok mintavételt vizsgálva igaz $H_0$ esetén t-eloszlású, aminek a pontos alakját egy darab szabadságfok szabályozza, ami most $df=n-p=n-k-1$, ami a Globális F-próbában a 2. szabadságfok volt.

Itt $H_0$ szempontjából a legjobb eset, ha $\beta_j=0$ a mintában is, hiszen $t=\frac{\beta_j}{SH_j}$. A t-eloszlás alakja miatt viszont így a p-értéket úgy kell számolni a 0 ponttól lefelé és felfelé vett eltérések esetén is csökkenjen a $H_0$ elutasításának hibavalószínűsége:

<center>
![](pt.jpg){width=50%}
</center>

<br>Így Pythonban a p-érték: `2*stats.t.cdf(-abs(0.0445/0.096), df = 102-4)`$= 0.644$. Ezt adja meg a `summary` metódus eredménytáblája a `P>|t|` oszlopban.

A `P>|t|` oszlopot nézegetve arra a kijelentésre juthatunk, hogy a COVID halálozásra a munkanélküliség és a 65 év feletti női népesség aránya is szignifikáns hatással van a *megfigyelt lakásokon kívüli világban is*, hiszen a parciális t-próba p-értéke az $\alpha=1\%$-os szignifikancia-szintnél is kisebb. Azaz a $H_0$ elvetésével mindkét magyarázóváltozó esetén elég alacsony valószínűséggel hibáznék. Ez a **Nok65Felett** változó esetében azt jelenti, hogy az a közepes-gyenge közvetlen hatása az árakra, amit a parciális korreláció (+0.29) kimutatott megmarad új járások vizsgálata esetén is. Ugyanakkor, azt is látni, hogy az **Apolok** változóhoz rendelt p-érték jóval nagyobb, mint a **Munkanelkuliseg** és **Nok65Felett** változóké. Konkrétan $64.4\%$ a p-érték, ami olyan magas, hogy a legmagasabb szokásos $\alpha$-nál, a $10\%$-nál is nagyobb, így stabilan elfogadhatom a próba $H_0$-ját! Tehát a parciális t-próba is azt mondja, hogy az **Apolok** változók hatása a COVID halálozásra a mintén kívüli filágban **nem szignifikáns**.

Végkonklúzióként, tehát azt vonhatjuk le a modellünk alapján, hogy az **ápolók számának COVID halálozásra gyakorolt pozitív hatása a kétváltozós regresszióban látszólagos volt csupán, és a munkanélküliség valamint 65 feletti női népesség arányának COVID halálozást növelő hatásait közvetítette csak, és semmi önálló szignifikáns marginális hatása nem volt**!

Ezek a változónkénti t-próba p-értékek azért nagyon jók, mert ezek alapján nagyon könnyű egy fontossági sorrendet felállítani a regressziónk magyarázóváltozói között. Az eddigiek alapján röviden-tömören: minél kisebb a parciális t-próba p-értéke, annál fontosabb az adott magyraázóváltozó az eredményváltozó előrejelezésében (annál kevésbé vehető marginális hatása $0$-nak a sokaságban)

## Magyarázóváltozók fontossági sorrendjének megállapítása t-próba alapján

Vegyük elő újra a <a href="https://github.com/KoLa992/Kovetkezteto-Statisztika-Python-Jegyzet/blob/main/BP_Lakas.csv" target="_blank">BP_Lakas.csv</a> fájlt, és töltsük be újra egy `pandas` data frame-be, ahogy a <a href="https://kola992.github.io/Kovetkezteto-Statisztika-Python-Jegyzet/k%C3%A9tv%C3%A1ltoz%C3%B3s-line%C3%A1ris-regresszi%C3%B3.html" target="_blank">12. fejezet</a> elején is tettük!

Előtte egy kis emlékeztető az adattábla tartalmáról, változóiról. A tábla 1406 budapesti lakásról 10 ismérv/változó (oszlop) adatát tárolja:

- KinArMFt: lakás ára millió Ft-ban (MFt)
- Terulet: lakás területe négyzetméterben
- Terasz: teraszok száma a lakásban
- Szoba: szobák száma a lakásban
- Felszoba: félszobák száma a lakásban
- Furdoszoba: fürdőszobák száma a lakásban
- Emelet: emeletek száma a lakásban
- DeliTaj: lakás déli fekvésű-e? (1 = igen; 0 = nem)
- Buda: lakás déli fekvésű-e? (1 = igen; 0 = nem)
- Kerulet: lakás kerülete (1 - 22)

Majd a konkrét beolvasás:

```{python}
BP_Lakas = pd.read_csv("BP_Lakas.csv")
BP_Lakas.info()
```

Most nem szenvedünk az adattípusokkal, mindent hagyunk numerikusan.

Nézzünk most meg egy olyan modellt a lakásárak becslésére, amiben  a **BP_Lakas** `data frame` minden változója szerepel magyarázóváltozóként a **Kerulet** kivételével:

```{python}
# eredményváltozó megadása
Y = BP_Lakas.KinArMFt

# magyarázóváltozók megadása a konstanshoz szükséges csupa 1 oszlop hozzáadásával
X = BP_Lakas.iloc[:,1:9]
X = sm.add_constant(X)

# létrehozzuk az új regressziót
nagymodell = sm.OLS(Y, X).fit()

# lássuk az eredménytáblát
print(nagymodell.summary())
```

Látjuk, hogy a modell magyarázóereje a mintában 81.76%, azaz a modellben lévő magyarázóváltozók együttesen kb. 82%-ban magyarázzák a lakásárak alakulását a megfigyelt 1406 lakás esetében. Ha a többi egyéb változó hatását is kiszűrjük, akkor a szobaszám közvetlen hatása $\alpha = 5\%$-on még éppen szignifikáns, de $\alpha = 1\%$-on már nem! A félszobák száma és az emeletek száma pedig egyik szokásos $\alpha$-n sem szignifikáns magyarázóváltozó már a megfigyelt lakásokon túli világban.

A magyarázóváltozók fontossági sorrendjét a változók p-értéke alapján növekvő sorba rendezéssel tudom megadni, mert minél kisebb a p-érték annál kisebb az esélye, hogy az adott $X_j$-t nem szignifikáns magyarázóváltozónak venni hibás döntés.

Ennek a folyamata egy kicsit macerás Pythonban. Először elmentjük a `summary` függvény eredményét egy külön Python változóba, és ennek a `tables` tulajdonságának a második (azaz 1. indexű) elemét olvasom ki egy következő külön változóba **html kódként, azaz <table> tagekkel!!**<br>
Ezt utána arra tudom használni, hogy a `pandas` csomag `read_html` függvényével be tudom olvasni a regresszió nagy együtthatótábláját a p-értékekkel együtt egy `data frame`-be. Arra kell még figyelni, hogy a *html* tábla 0. indexű sora legyen a `read_html`-el beolvasott `data frame` sorindexe (`index_col` paraméter) és ugyan ezen tábla 0. indexű oszlopa pedig legyen ugyanitt az oszlopfejléc (`header` paraméter).<br>
Annyi technikai dologra kell még odafigyelni, hogy a `read_html` függvény egy egyelemű listaként adja vissza az eredményt, így ahhoz, hogy közvetlenül a `data frame`-t kapjuk vissza, ennek az eredménylistának a 0. indexű elemét külön ki kell venni `[0]` kódrészlettel a végén.<br>
Lássuk is hát a konkrét Python kódokat és az eredményül kapott `data frame`-et!

```{python warnings=FALSE}
BetaTablaHTML = nagymodell.summary().tables[1].as_html()
BetaTabla_df = pd.read_html(BetaTablaHTML, header=0, index_col=0)[0]
BetaTabla_df
```

Ha megvan a `data frame`, akkor pedig rendezzük növekvő sorrendbe a 4. (3. indexű) oszlop, azaz a $\beta_j$ együtthatók **p-értékei** szerint. Előtte a tengelymetszet ($\beta_0$) sorát, a `const`-t kihagyjuk a `data frame`-ből, mert ugyebár az nem egy magyarázóváltozó együtthatója a regressziós egyenletben.

```{python}
BetaTabla_df.iloc[1:9,:].sort_values(by=BetaTabla_df.columns[3])
```

Láthatjuk, hogy a Terület a legfontosabb magyarázóváltozó, míg a pl. szobák száma a *3. legkevésbé fontos* magyarázóváltozó.

## 5. Konfidencia-intervallumok és a t-próba kapcsolata

A többváltozós regressziós modell együtthatóira (béták) is lehet egy adott megbízhatósági szintű konfidencia-intervallumot is készíteni Pythonban a regressziós modellek `confint` metódusának segítségével.<br>
Pl. **egy 97% megbízhatóságú konfidencia-intervallum $\beta_j$-re azt adja meg, hogy 97%-os valószínűséggel milyen értékhatárok között mozoghat $\beta_j$ együttható a megfyigelt lakásokon túli világban**.

Nézzük is meg a Python számítást:

```{python}
nagymodell.conf_int() # alapból 95%-os megbízhatóságú

nagymodell.conf_int(alpha = 0.03) # de lehet pl. 97%-os is (alfa = 1-0.97)
```

Pl. az első eredménytábla alapján a **Terulet** változó $\beta$-ja 95%-os valószínűséggel 0.277 és 0.317 között kötne ki valahol, ha nem 1406 budapesti lakást vizsgálnánk, hanem az össeset (azaz a lakások sokaságát).

Az eredményből megjelenik egy olyan összefüggés is, miszerint, **ha egy $X_j$ nem szignifikáns $\alpha$ szignifikancia-szinten, akkor az $1-\alpha$ megbízhatóságú konfidencia-intervallumának határai előjelet váltanak**.<br>
legjobb példa a **Szoba** változó esete: azt mondtuk rá, hogy hatása az árakra 5%-on még épp szignifikáns -> a 95%-os megbízhatóságú intervalluma még épp nem vált előjelet. Viszont a változó 3%-on már nem szignifikáns, így az intervalluma előjelet vált.

Ezzel egy érdekes nézőponthoz jutottunk: *ha egy $X_j$ változó nem szignifikáns $\alpha$-n az azt jelenti, hogy $1-\alpha$ megbízhatósági szinten azt sem tudom eldönteni, hogy minden más változatlansága mellett +1 egység $X_j$ növeli vagy csökkenti-e az eredmányváltozót a mintán kívüli világban*.

A háttérben amúgy annyi történik, hogy a Python kiszámolja a parciális t-próba esetén is alkalmazott $n-p=n-k-1$ szabadságfokú t-eloszlás inverz értékét $1-\alpha/2$ valószínűség mellett, és az ezzel beszorzott standard hibát adja hozzá és vonja le $\forall \beta_j$-ből:

```{python}
BetaTabla_df

alfa = 0.02
p = len(BetaTabla_df) # így a tengelymetszetet is beszámítjuk p-be
n = len(BP_Lakas) # mintaelemszám
szorzo = stats.t.ppf(1-alfa/2, df = n-p)

Terulet_AH = BetaTabla_df.iloc[1,0] - szorzo * BetaTabla_df.iloc[1,1] # Terulet 98% alsó határ
Terulet_FH = BetaTabla_df.iloc[1,0] + szorzo * BetaTabla_df.iloc[1,1] # Terulet 98% felső határ
print([Terulet_AH, Terulet_FH])
```

Formális képlettel leírva a műveletet:

<center>
![](BetaCI.jpg){width=50%}
</center>

## Nominális magyarázóváltozók - Használtautó adatok

Most egy új, <a href="https://github.com/KoLa992/Kovetkezteto-Statisztika-Python-Jegyzet/blob/main/auto.xlsx" target="_blank">auto.xlsx</a> fájlból fogunk dolgozni, ami 100 db használtautóról tartalmaz 8 változót:

- Vetelar: Vételár Ft-ban
- Kor: Az autó kora években
- Kilometerora: A kilóméteróra állása
- Teljes_tomeg: Az autó tömege kg-ban
- Hengerurtartalom: Hengerűrtartalom *ccm*-ben (köbcenti)
- Teljesitmeny: A motor teljesítménye Kw/h-ban
- Allapot: Az autó állapota szöveges minősítéssel
- Uzemanyag: Üzemanyag típusa (benzin/dízel)

Láthatjuk, hogy ez nem *csv*, hanem Excel, azaz *xlsx* fájl. Úgyhogy olvassuk is be egy pandas `data frame`-be!

```{python}
autok = pd.read_excel("auto.xlsx")
autok.info()
```

Minden szupinak néz ki! Megvan mind a 100 megfigyelési egység és a 8 db változó.

Vessünk még egy pillantást arra, hogy az **Allapot** változónak milyen lehetséges értékei vannak:

```{python}
autok.Allapot.unique()
```

## Dummy változók és működésük Pythonban

No, ha egy sima OLS regresszióba magyarázóváltozóként nominális változót akarunk bevenni, mint amilyen jelen példánkban az **Allapot** vagy az **Uzemanyag**, akkor az R az úgynevezett **dummy-kódolást** veti be. A nominális változó lehetséges értékeiből kiválaszt egyet, mint **referencia kategória**, azt "*elteszi*", és a maradéknak pedig csinál külön-külön egy *bináris = dummy* változót, aminek értéke 1, ha a megfigyelés a vizsgált szöveges változóban épp a dummy változónak megfelelő értéket vesz fel, egyébként 0:

<center>
![](Dummy.jpg){width=50%}
</center>

A fenti táblázatban az $R_A$ és $R_B$ lennének a regresszióban használt dummy változók, és a referencia kategória a $C$ érték. Ezt a $C$ kategóriát azért nem szabad a modellben szerepeltetni, mert egyértelmű, hogy ha $D_A=0$ és $D_B=0$, akkor $D_C=1$. Ezzel egy teljesen redundáns magyarázóváltozót raknánk a modellbe, amitől az egész rendszer megdöglik, mert a $\beta$-k becslése során alkalmazott $\beta=(X^TX)^{-1}X^Ty$ képletben az $(X^TX)^{-1}$ inverzet nem lehet elvégezni, ha $X$ mátrix oszlopai olyanok, hogy az egyiket hibátlanul elő lehet állítani a többiből. Ez a jelenség az **egzakt multikollinearitás** nevet kapta a keresztségben.

Ezekkel a megfontolásokkal lássunk is neki a dummy változóink legyártásához a két nominális változónk (**Uzemanyag** és **Allapot**) esetében!<br>
Először a `pandas` csomag `get_dummies` függvényével létrehozzuk a két szöveges változó minden kategóriájához a megfelelő 0/1, azaz dummy változókat. A függvény első paramétere az érintett változókat tartalmazó `data frame`, a második (`columns`) azon oszlopnevek listája, amelyekből dummy változókat akarunk csinálni, még az utolsó, `dtype` paraméterben a dummy változók adattípusát lehet megadni. Ez utolsó paraméter azért szükséges, mert egy dummy változó logikusan lehet akár `bool` adattípusú, de ad abszurdum `int` is. Most mi ez utóbbi opcióval megyünk, mert a `statsmodels` csomag nem tud `bool` típusú váltizókkal dolgozni.

```{python}
autok_dummy = pd.get_dummies(autok, columns=['Uzemanyag', 'Allapot'], dtype=int)
autok_dummy.info()
```

Szuper, megvan minden szükséges új változó, és a megfelelő, azaz `int` adattípuson is vannak!

Ezek után lássunk hozzá a regressziós modell legyártásához, amely az autók vételárát magyarázza az összes többi változóval a táblában. Arra kell figyelni, hogy a magyarázóváltozók ($X$ mátrix) kijelölésénél ne válasszuk ki a két nominális változó refrencia kategóriáinak oszlopait. Legyen most az **Uzemanyag** változó esetén a kihagyott refrencia kategória a *Benzin* (6. oszlopindex), míg **Allapot** esetén a *Kituno* (8. oszlopindex).

```{python}
Y = autok_dummy.Vetelar
X = autok_dummy.iloc[:,[1,2,3,4,5,7,9,10,11,12]] # megfelelő oszlopindexek kiválasztása
X = sm.add_constant(X)

# létrehozzuk az új regressziót
autos_modell = sm.OLS(Y, X).fit()

# lássuk az eredménytáblát
print(autos_modell.summary())
```

Úgy néz ki rendben vagyunk, a magyarázóváltozók együttesen $72.8\%$-ban magyraázzák az autók vételárának alakulását.

Nézzük meg a nominális magyarázóváltozókhoz köthető dummy változók $\beta_j$ együtthatóinak értelmezését! Az eddigi okoskodásaink alapján alapján az egyes együtthatók értelmezése mindig a **referencia kategóriához** képest értednő:

- $\beta_{Dizel}=-37630$: Minden más magyarázóváltozó változatlansága mellett egy dízelautó várhatóan 37630 Ft-al lesz olcsóbb, mint egy *benzines*.
- $\beta_{Normal}=-119200$: Minden más magyarázóváltozó változatlansága mellett egy normál állapotú autó várhatóan kb. 119 200 Ft-tal lesz olcsóbb, mint egy *kitűnő* állapotban lévő.

### Referencia kategória megváltoztatása

Az előző modellben nem feltétlenül a legszerencsésebb az, ha a *Kituno* a referencia kategória az **Allapot** változóban. Logikusabb lenne a *Normal* állapotot referenciának venni. A módosítást simán meg tudjuk tenni. Egyszerűen az $X$ mátixból a 10. oszlopindexet hagyom ki a 8. helyett, és így újrafuttatom a modellt.

Alapvetően a `levels` függvény eredményéből látható, hogy a referencia kategória az **Allapot** változóban azért a volt a *Kituno*, mert az van betűrend szerint a legelöl az **Allapot** változó lehetséges értékei közül:

```{python}
X = autok_dummy.iloc[:,[1,2,3,4,5,7,8,9,11,12]] # megfelelő oszlopindexek kiválasztása
X = sm.add_constant(X)

# újra lefuttatjuk a regressziót
autos_modell = sm.OLS(Y, X).fit()

# lássuk az eredménytáblát
print(autos_modell.summary())
```

Így már azt mondhatom, hogy egy kitűnő állapotban lévő autó várhatóan $\beta_{Kituno}=+119200$ Ft-tal kerül többe egy normál állapotú autónál minden egyéb változó változatlansága mellett. Teljesen logikus módon abszolút értékben ugyan akkora a hatás az árakra, mint az előző modellben, ahol a *Kituno* vot a referencia kategória és $\beta_{Normal}=-119200$-t viszgáltuk, csak ellentétes előjelű.

## A korrigált R-négyzet mutató

Az előző fejezet végi modell eredménytáblázatát elnézegetve azt láthatjuk, hogy a modell két legkevésbé fontos, azaz legmagasabb p-értékű magyarázóváltozója a **Hengerurtartalom** és a **Teljes_tomeg**. Ha ezeknek a változóknak tényleg nincs közük az autók vételárához, akkor egy logikus gondolat, hogy potyogtassuk is ki őket a modellünkből! Ha emlékszünk még az `autok_dummy` táblára, akkor tudhatjuk, hogy ez a két változó rendre a 4. és 3. oszlopindexen futott, szóval csak ezeket az oszlopokat kell kiszedni az $X$ mátrixból, és már meg is szabadultunk ezektől a azvaró tényezőktől.

```{python}
X_szuk = autok_dummy.iloc[:,[1,2,5,7,8,9,11,12]] # megfelelő oszlopindexek kiválasztása
X_szuk = sm.add_constant(X_szuk)

# újra lefuttatjuk a regressziót
autos_modell_szuk = sm.OLS(Y, X_szuk).fit()

# lássuk az eredménytáblát
print(autos_modell_szuk.summary())
```

Első ránézésre minden rendben, de nézzük csak össze ennek a szűkített modellnek az $R^2$ értékét az eredeti modell $R^2$ értékével, ami még tartalmazta a hengerűrtartalmat és a teljes tömeget! Ezt legkönnyebben úgy tudjuk megkérdezni, hogy mindkét modellnek lekérdezzük az `rsquared` tulajdonságát.

```{python}
[autos_modell.rsquared, autos_modell_szuk.rsquared]
```

Ajjaj! A modellünk magyarázóereje leromlott $72.72\%$-ra az eredeti $72.79\%$-ról! De hát azért eléggé nem szignifikánsnak kinéző változókat szedtünk ki! A legalacsonyabb t-próba p-érték $65.9\%$ volt a kihagyott magyarázóváltozók között (**Teljes_tomeg**)! Miért csökken az $R^2$?

Sajnos a jó öreg $R^2$ nem fog soha javulni akkor, ha a modellből elhagyunk egy magyarázóváltozót. Legyen az bármennyire is haszontalan.

Miért is? Ugye $R^2=1-\frac{SSE}{SST}$ és hát $SSE$ minimalizálásával szüljük meg a $\beta_j$ együtthatókat. Konkrétan úgy választjük meg az értéküket, hogy a MEGFIGYELT $y$ értékekre a lehető legjobban illeszkedjen a regresszióból nyert $\hat{y}$ becslés!

Ezt az illeszkedést pedig egy újabb magyarázóváltozó bevonása biztosan NEM RONTJA el, legyen bármennyire irreleváns $y$ szempontjából. Hiszen eggyel több $\beta_j$ van arra, hogy minimalizáljuk a modellhibát ($SSE$). De ha kilépünk a megfigyeléseinken túli világba (sokaságba), akkor már az $\hat{y}$ becslések jóságát elrontják ezek az irreleváns magyarázóváltozók a modellben. Ez a jelenség a **túltanítás** jelensége!

Nézzük ezt meg az alábbi képen:

<center>
![](Tultan1.jpg){width=100%}
</center>

A pontokra illesztett görbék mögött a következő egyenletek vannak:

- Lineáris = $5.13x-0.46$
- Harmadfokú = $2.48x^3+3.17x^2−1.06x +1.08$
- Hetedfokú = $−7426x^7+28047x^6−42886x^5+33991x^4−14814x^3+3457x^2−380x+14$

Az ábráról láthatjuk, hogy a pontokra a legreálisabb illeszkedést a 3 db magyarázóváltozót ($x^3, x^2, x$) használó *Harmadfokú* görbe adja. De az $R^2$ mégis a legtöbb magyarázóváltozót használó Hetedfokú opciót részesíti előnyben a *túltanulás* miatt!

Ennek kiküszöbölésére bevezetjük a korrigált $R^2$ mutatót:

<center>
![](AdjR2.jpg){width=50%}
</center>

A korrekciós képlet lényege, hogy ez a mutató csökkenhet is, ha irreleváns (erősen nem szignifikáns) magyarázóváltozókat vonunk be a modellbe. Ezért van a képletben a megfigyelések száma ($n$) mellett a magyarázóváltozók száma, $k$ is.

Láthatjuk, hogy a korábbi példánkban $\bar{R}^2$ már a harmadfokú modellt preferálja, nagyon helyesen!

<center>
![](Tultan2.jpg){width=100%}
</center>

A $\bar{R}^2$ mutató értékét megtaláljuk a sima `summary` függvény eredménytáblájában is, de praktikusabb lekérdezni, mint a regressziós modellek `rsquared_adj` tulajdonsága.

```{python}
[autos_modell.rsquared_adj, autos_modell_szuk.rsquared_adj]
```

Hurrá! Láthatjuk, hogy a korrigált R-négyzet már heylesen azt mutatja, hogy a nem szignifikáns változók kihagyásával kapott szűkített modell magyarázóereje nagyobb ($70.3\%$), mint az eredeti modellé ($69.7\%$), amiben ez a két haszontalan változó is benne volt.